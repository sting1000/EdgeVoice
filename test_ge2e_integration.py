#!/usr/bin/env python3
"""
GE2E Loss é›†æˆæµ‹è¯•è„šæœ¬

è¯¥è„šæœ¬ç”¨äºŽå¿«é€ŸéªŒè¯GE2E Lossä¸ŽStreamingConformeræ¨¡åž‹çš„å®Œæ•´é›†æˆï¼Œ
ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚

ä½¿ç”¨æ–¹æ³•:
    python test_ge2e_integration.py

ä½œè€…: EdgeVoiceé¡¹ç›®  
æ—¥æœŸ: 2024
"""

import torch
import torch.nn.functional as F
import numpy as np
import sys
import os
from typing import List, Tuple

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from models.streaming_conformer import StreamingConformer
from models.ge2e_loss import GE2ELoss, GE2EBatchSampler
from config import *


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯• 1: åŸºæœ¬åŠŸèƒ½éªŒè¯")
    print("=" * 60)
    
    print("1.1 æµ‹è¯•GE2E LossåŸºæœ¬åŠŸèƒ½...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size = 32  # 4ä¸ªå…³é”®è¯ * 8æ¡éŸ³é¢‘
    embedding_dim = 128
    num_phrases = 4
    num_utterances_per_phrase = 8
    
    embeddings = torch.randn(batch_size, embedding_dim)
    criterion = GE2ELoss()
    
    try:
        loss = criterion(embeddings, num_phrases, num_utterances_per_phrase)
        print(f"   âœ“ GE2E Loss è®¡ç®—æˆåŠŸ: {loss.item():.4f}")
        
        # æµ‹è¯•åå‘ä¼ æ’­
        loss.backward()
        print("   âœ“ åå‘ä¼ æ’­æˆåŠŸ")
        
    except Exception as e:
        print(f"   âœ— GE2E Loss æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\n1.2 æµ‹è¯•StreamingConformeråµŒå…¥å‘é‡è¾“å‡º...")
    
    # åˆ›å»ºæ¨¡åž‹
    model = StreamingConformer(
        input_dim=48,
        hidden_dim=128,
        num_classes=4,
        num_layers=3,
        dropout=0.1
    )
    
    # æµ‹è¯•åµŒå…¥å‘é‡è¾“å‡º
    input_features = torch.randn(4, 100, 48)  # [batch, seq_len, feature_dim]
    
    try:
        # æµ‹è¯•get_embeddingsæ–¹æ³•
        embeddings = model.get_embeddings(input_features)
        print(f"   âœ“ get_embeddingsè¾“å‡ºå½¢çŠ¶: {embeddings.shape}")
        
        # æµ‹è¯•forward_with_embeddingsæ–¹æ³•
        logits, embeddings2 = model.forward_with_embeddings(input_features)
        print(f"   âœ“ forward_with_embeddings - logits: {logits.shape}, embeddings: {embeddings2.shape}")
        
        # éªŒè¯åµŒå…¥å‘é‡æ˜¯å½’ä¸€åŒ–çš„
        norms = torch.norm(embeddings, p=2, dim=1)
        print(f"   âœ“ åµŒå…¥å‘é‡L2èŒƒæ•°: {norms.mean().item():.4f} (åº”è¯¥æŽ¥è¿‘1.0)")
        
    except Exception as e:
        print(f"   âœ— StreamingConformer æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("   âœ“ åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_batch_sampler():
    """æµ‹è¯•æ‰¹æ¬¡é‡‡æ ·å™¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æ‰¹æ¬¡é‡‡æ ·å™¨éªŒè¯")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ ‡ç­¾
    labels = []
    num_classes = 4
    samples_per_class = 20
    
    for class_id in range(num_classes):
        labels.extend([class_id] * samples_per_class)
    
    print(f"æ¨¡æ‹Ÿæ•°æ®é›†: {num_classes} ä¸ªç±»åˆ«, æ¯ä¸ªç±»åˆ« {samples_per_class} ä¸ªæ ·æœ¬")
    
    try:
        # åˆ›å»ºæ‰¹æ¬¡é‡‡æ ·å™¨
        batch_sampler = GE2EBatchSampler(
            labels=labels,
            num_phrases_per_batch=4,
            num_utterances_per_phrase=8,
            shuffle=True
        )
        
        print(f"   æ‰¹æ¬¡é‡‡æ ·å™¨åˆ›å»ºæˆåŠŸï¼Œæ€»æ‰¹æ¬¡æ•°: {len(batch_sampler)}")
        
        # æµ‹è¯•ç”Ÿæˆæ‰¹æ¬¡
        batch_count = 0
        for batch_indices in batch_sampler:
            batch_count += 1
            batch_labels = [labels[i] for i in batch_indices]
            
            # éªŒè¯æ‰¹æ¬¡ç»“æž„
            if len(batch_indices) != 32:  # 4 * 8
                raise ValueError(f"æ‰¹æ¬¡å¤§å°é”™è¯¯: {len(batch_indices)}")
            
            # éªŒè¯æ¯ä¸ªç±»åˆ«éƒ½æœ‰8ä¸ªæ ·æœ¬
            from collections import Counter
            label_counts = Counter(batch_labels)
            
            if len(label_counts) != 4:
                raise ValueError(f"æ‰¹æ¬¡ä¸­ç±»åˆ«æ•°é”™è¯¯: {len(label_counts)}")
            
            for count in label_counts.values():
                if count != 8:
                    raise ValueError(f"ç±»åˆ«æ ·æœ¬æ•°é”™è¯¯: {count}")
            
            if batch_count >= 3:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
                break
        
        print(f"   âœ“ æ‰¹æ¬¡ç»“æž„éªŒè¯é€šè¿‡ï¼Œæµ‹è¯•äº† {batch_count} ä¸ªæ‰¹æ¬¡")
        
    except Exception as e:
        print(f"   âœ— æ‰¹æ¬¡é‡‡æ ·å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True


def test_end_to_end_training():
    """æµ‹è¯•ç«¯åˆ°ç«¯è®­ç»ƒ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: ç«¯åˆ°ç«¯è®­ç»ƒéªŒè¯")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡åž‹å’ŒæŸå¤±å‡½æ•°
        model = StreamingConformer(
            input_dim=48,
            hidden_dim=96,  # ä½¿ç”¨è¾ƒå°çš„æ¨¡åž‹åŠ å¿«æµ‹è¯•
            num_classes=4,
            num_layers=2,
            dropout=0.1
        )
        
        criterion = GE2ELoss(init_w=10.0, init_b=-5.0)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            list(model.parameters()) + list(criterion.parameters()),
            lr=1e-3
        )
        
        print("   æ¨¡åž‹å’Œä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        num_phrases = 4
        num_utterances_per_phrase = 8
        batch_size = num_phrases * num_utterances_per_phrase
        
        input_features = torch.randn(batch_size, 50, 48)  # è¾ƒçŸ­çš„åºåˆ—é•¿åº¦
        
        print("   å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒ...")
        
        # è®°å½•è®­ç»ƒè¿‡ç¨‹
        losses = []
        
        for epoch in range(5):  # è®­ç»ƒ5ä¸ªepoch
            model.train()
            
            # å‰å‘ä¼ æ’­
            embeddings = model.get_embeddings(input_features)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(embeddings, num_phrases, num_utterances_per_phrase)
            losses.append(loss.item())
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            
            print(f"   Epoch {epoch+1}: Loss = {loss.item():.4f}, w = {criterion.w.item():.2f}, b = {criterion.b.item():.2f}")
        
        # éªŒè¯è®­ç»ƒæ•ˆæžœ
        if len(losses) >= 2:
            if losses[-1] < losses[0]:
                print("   âœ“ æŸå¤±å‡½æ•°åœ¨ä¸‹é™ï¼Œè®­ç»ƒæ­£å¸¸")
            else:
                print("   ! æŸå¤±å‡½æ•°æœªæ˜Žæ˜¾ä¸‹é™ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°")
        
        print("   âœ“ ç«¯åˆ°ç«¯è®­ç»ƒæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"   âœ— ç«¯åˆ°ç«¯è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def test_inference_workflow():
    """æµ‹è¯•æŽ¨ç†å·¥ä½œæµç¨‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: æŽ¨ç†å·¥ä½œæµç¨‹éªŒè¯")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡åž‹
        model = StreamingConformer(
            input_dim=48,
            hidden_dim=96,
            num_classes=4,
            num_layers=2,
            dropout=0.1
        )
        model.eval()
        
        print("   4.1 æµ‹è¯•è´¨å¿ƒè®¡ç®—...")
        
        # æ¨¡æ‹Ÿæ³¨å†Œé˜¶æ®µ - æ¯ä¸ªå…³é”®è¯å¤šä¸ªæ ·æœ¬
        num_keywords = 4
        samples_per_keyword = 5
        
        registration_features = torch.randn(num_keywords * samples_per_keyword, 50, 48)
        
        with torch.no_grad():
            registration_embeddings = model.get_embeddings(registration_features)
        
        # è®¡ç®—æ¯ä¸ªå…³é”®è¯çš„è´¨å¿ƒ
        centroids = []
        for i in range(num_keywords):
            start_idx = i * samples_per_keyword
            end_idx = start_idx + samples_per_keyword
            
            keyword_embeddings = registration_embeddings[start_idx:end_idx]
            centroid = F.normalize(keyword_embeddings.mean(dim=0, keepdim=True), p=2, dim=1)
            centroids.append(centroid)
        
        centroids = torch.cat(centroids, dim=0)
        print(f"   âœ“ è´¨å¿ƒè®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {centroids.shape}")
        
        print("   4.2 æµ‹è¯•å•æ ·æœ¬æŽ¨ç†...")
        
        # æ¨¡æ‹Ÿæµ‹è¯•æ ·æœ¬
        test_sample = torch.randn(1, 50, 48)
        
        with torch.no_grad():
            test_embedding = model.get_embeddings(test_sample)
            
            # è®¡ç®—ä¸Žæ‰€æœ‰è´¨å¿ƒçš„ç›¸ä¼¼åº¦
            similarities = torch.matmul(test_embedding, centroids.T)
            
            # é¢„æµ‹
            best_match = torch.argmax(similarities, dim=1)
            confidence = torch.max(similarities, dim=1)[0]
        
        print(f"   âœ“ æŽ¨ç†å®Œæˆ - æœ€ä½³åŒ¹é…: å…³é”®è¯{best_match.item()}, ç½®ä¿¡åº¦: {confidence.item():.4f}")
        
        print("   4.3 æµ‹è¯•æ‰¹é‡æŽ¨ç†...")
        
        # æ¨¡æ‹Ÿæ‰¹é‡æµ‹è¯•
        batch_test_samples = torch.randn(10, 50, 48)
        
        with torch.no_grad():
            batch_embeddings = model.get_embeddings(batch_test_samples)
            batch_similarities = torch.matmul(batch_embeddings, centroids.T)
            
            batch_predictions = torch.argmax(batch_similarities, dim=1)
            batch_confidences = torch.max(batch_similarities, dim=1)[0]
        
        print(f"   âœ“ æ‰¹é‡æŽ¨ç†å®Œæˆï¼Œå¤„ç† {len(batch_test_samples)} ä¸ªæ ·æœ¬")
        print(f"     å¹³å‡ç½®ä¿¡åº¦: {batch_confidences.mean().item():.4f}")
        
    except Exception as e:
        print(f"   âœ— æŽ¨ç†å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("   âœ“ æŽ¨ç†å·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("GE2E-KWS Loss é›†æˆæµ‹è¯•")
    print("åŸºäºŽè®ºæ–‡: arXiv:2410.16647v1")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    tests = [
        ("åŸºæœ¬åŠŸèƒ½", test_basic_functionality),
        ("æ‰¹æ¬¡é‡‡æ ·å™¨", test_batch_sampler),
        ("ç«¯åˆ°ç«¯è®­ç»ƒ", test_end_to_end_training),
        ("æŽ¨ç†å·¥ä½œæµç¨‹", test_inference_workflow),
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for test_name, test_func in tests:
        print(f"\næ­£åœ¨è¿è¡Œæµ‹è¯•: {test_name}")
        try:
            if test_func():
                passed_tests += 1
                print(f"âœ“ {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âœ— {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âœ— {test_name} æµ‹è¯•å‡ºé”™: {e}")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print(f"é€šè¿‡æµ‹è¯•: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GE2E Loss å®žçŽ°å·²å‡†å¤‡å°±ç»ªã€‚")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡æ‚¨çš„éŸ³é¢‘æ•°æ®å’Œæ ‡æ³¨æ–‡ä»¶")
        print("2. è¿è¡Œå®Œæ•´ç¤ºä¾‹: python examples/ge2e_example.py")
        print("3. å¼€å§‹è®­ç»ƒ: python train_ge2e.py --help")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®žçŽ°ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 