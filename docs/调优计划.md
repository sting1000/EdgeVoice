# 优化模型达到95%准确率的方案

## 第一阶段：核心说法优化方案

### 1. 模型架构优化

**模型调整**：
- 增加Conformer层数到6层（原来是4层）：`CONFORMER_LAYERS = 6`
- 增加隐藏层维度到128：`CONFORMER_HIDDEN_SIZE = 128`
- 增加注意力头数到12：`CONFORMER_ATTENTION_HEADS = 12`
- 修改config.py中的类别设置，确保有明确的"OTHERS"类别

**具体步骤**：
```python
# 修改config.py中的模型参数
CONFORMER_LAYERS = 6
CONFORMER_HIDDEN_SIZE = 128
CONFORMER_ATTENTION_HEADS = 12
CONFORMER_DROPOUT = 0.3  # 增加dropout防止过拟合
```

### 2. 数据集设计

**核心说法数据采集规则**：
- 每个意图收集至少150条严格核心说法样本
- 每个意图的核心说法集中在1-3个关键短语上
- 确保录音环境多样性，但语音清晰度高
- 说话者多样性：年龄、性别、口音覆盖广泛
- 噪音控制：安静环境录制为主，保证基础质量

**负样本设计**：
- 采集大量"OTHERS"类别样本（至少是正样本总数的2倍）
- 负样本包括:
  1. 日常对话中的常见短句
  2. 与正样本相似但不同意图的表达
  3. 相似语音模式的不相关短语
  4. 不同长度的背景噪声

**数据分布**：
- 训练集:验证集:测试集 = 70%:15%:15%
- 确保各集合中的说话者没有重叠
- 每个意图在各数据集中的比例保持一致

### 3. 训练策略优化

**改进训练过程**：
```python
# 修改config.py中的训练参数
BATCH_SIZE = 48
LEARNING_RATE = 1e-4  # 降低学习率提高稳定性
NUM_EPOCHS = 50  # 增加训练轮数
LABEL_SMOOTHING = 0.1  # 减小标签平滑系数
EARLY_STOPPING_PATIENCE = 12  # 增加早停耐心值
```

**数据增强策略**：
- 增加增强的强度和多样性：
```python
# 修改config.py中的数据增强参数
AUGMENT_PROB = 0.9  # 提高增强概率
NOISE_STD = 0.02  # 增加噪声标准差
USE_SPEED_PITCH_AUGMENT = True  # 添加速度和音高变化增强
SPEED_FACTOR_RANGE = [0.9, 1.1]  # 速度变化范围
PITCH_FACTOR_RANGE = [-2, 2]  # 音高变化范围
```

**负样本处理**：
- 实现难例挖掘机制：
```python
# 在train_streaming.py中添加难例挖掘函数
def mine_hard_negatives(model, dataset, k=500):
    """挖掘难分类的负样本"""
    model.eval()
    hard_negatives = []
    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="挖掘难例"):
            features, labels = batch
            features = features.to(DEVICE)
            outputs = model(features)
            probs = F.softmax(outputs, dim=1)
            
            # 找出被误分类为正样本的负样本
            for i, (prob, label) in enumerate(zip(probs, labels)):
                if label == dataset.label_to_id["OTHERS"]:
                    # 如果负样本的最高置信度不是"OTHERS"类
                    if torch.argmax(prob).item() != dataset.label_to_id["OTHERS"]:
                        hard_negatives.append(dataset.df.iloc[i].name)
                        
                        if len(hard_negatives) >= k:
                            break
    
    return hard_negatives
```

## 第二阶段：扩展支持更多说法

### 1. 模型架构扩展

**扩展模型能力**：
- 进一步增加模型容量：
```python
# 修改config.py中的模型参数
CONFORMER_LAYERS = 8
CONFORMER_HIDDEN_SIZE = 192
CONFORMER_ATTENTION_HEADS = 16
```

- 添加更高级的特征提取：
```python
# 修改utils/feature_extraction.py启用增强特征
def extract_features(audio, sr, use_enhanced_features=True):
    extractor = FeatureExtractor(
        sample_rate=TARGET_SAMPLE_RATE,
        n_mfcc=N_MFCC,
        enhanced_features=use_enhanced_features
    )
    return extractor.extract_features(audio)
```

### 2. 数据集扩展设计

**表达方式扩展**：
- 每个意图增加至少10种不同表达方式
- 每种表达方式收集50-100个样本
- 分类记录不同表达方式的识别准确率
- 建立表达方式相似度矩阵，分析混淆模式

**分层数据集**：
- 将数据集分为三层:
  1. 核心说法（第一阶段数据）
  2. 常见变体（语法、词序变化的表达）
  3. 扩展表达（意图相同但表达方式差异大的说法）

**语料采集规则**：
- 使用引导式采集法收集自然表达
- 收集不同场景下的表达方式（语境差异）
- 确保覆盖不同语速、音高、停顿模式
- 为每种表达方式标注亲和度分数（与核心说法的相似度）

### 3. 训练策略升级

**增量训练**：
- 实现增量式训练流程：
```python
def incremental_training(base_model_path, new_data_path, fine_tune_learning_rate=5e-5):
    """增量训练函数，基于已有模型适应新表达方式"""
    # 加载基础模型
    model = StreamingConformer(
        input_dim=get_feature_dim(),
        hidden_dim=CONFORMER_HIDDEN_SIZE,
        num_classes=len(INTENT_CLASSES),
        num_layers=CONFORMER_LAYERS,
        num_heads=CONFORMER_ATTENTION_HEADS
    )
    model.load_state_dict(torch.load(base_model_path))
    model = model.to(DEVICE)
    
    # 冻结某些层，只微调上层
    for name, param in model.named_parameters():
        if "layers.0" in name or "layers.1" in name:
            param.requires_grad = False
    
    # 准备新数据
    train_loader, val_loader, intent_labels = prepare_data_loaders(
        annotation_file=new_data_path,
        batch_size=BATCH_SIZE,
        valid_annotation_file=None,
        val_split=0.15
    )
    
    # 设置优化器
    optimizer = optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=fine_tune_learning_rate,
        weight_decay=0.01
    )
    
    # 设置学习率调度器
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=NUM_EPOCHS * len(train_loader)
    )
    
    # 训练
    for epoch in range(NUM_EPOCHS):
        train_epoch(model, train_loader, optimizer, criterion, scheduler=scheduler)
        val_loss, val_acc = validate(model, val_loader, criterion)
        
        print(f"Epoch {epoch+1}/{NUM_EPOCHS}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
    
    return model
```

**混合训练策略**：
- 结合使用原始数据和新表达方式数据：
```python
def mix_data_for_training(core_expressions_file, extended_expressions_file, mix_ratio=0.3):
    """混合核心说法和扩展说法数据"""
    # 读取核心说法数据
    core_df = pd.read_csv(core_expressions_file)
    
    # 读取扩展说法数据
    extended_df = pd.read_csv(extended_expressions_file)
    
    # 计算每个意图需要的扩展样本数
    intent_counts = {}
    for intent in core_df['intent'].unique():
        core_count = len(core_df[core_df['intent'] == intent])
        ext_available = len(extended_df[extended_df['intent'] == intent])
        
        # 计算要添加的扩展样本数
        ext_count = min(int(core_count * mix_ratio), ext_available)
        intent_counts[intent] = ext_count
    
    # 随机选择扩展样本
    selected_extended = []
    for intent, count in intent_counts.items():
        intent_samples = extended_df[extended_df['intent'] == intent].sample(count)
        selected_extended.append(intent_samples)
    
    # 合并数据
    mixed_df = pd.concat([core_df] + selected_extended)
    mixed_df = mixed_df.sample(frac=1).reset_index(drop=True)  # 打乱数据
    
    return mixed_df
```

## 实施计划

### 第一阶段实施步骤

1. **准备核心说法数据集**
   - 设计核心表达方式清单，每个意图2-3个核心表达
   - 招募多样性说话者（性别、年龄、口音）
   - 使用工具采集高质量录音（安静环境）
   - 细致标注数据（意图类别、说话者信息）

2. **模型基础训练**
   - 修改config.py中的模型参数
   - 实现数据增强流程
   - 训练基础模型（使用早停防止过拟合）
   - 在验证集上评估，确保准确率超过95%

3. **负样本优化**
   - 挖掘难例，找出易误识别的负样本
   - 添加更多负样本样式和变体
   - 重新训练模型，关注误识别为正样本的样本减少

4. **评估与调优**
   - 在独立测试集上评估模型性能
   - 分析错误样本，找出模式
   - 根据错误模式调整模型参数
   - 反复迭代直到达到95%准确率且误识别低

### 第二阶段实施步骤

1. **扩展表达方式数据集**
   - 设计不同表达方式清单（每个意图10+种表达）
   - 采集新的表达方式数据
   - 对数据进行分类（常见变体、扩展表达）
   - 详细标注数据（表达类型、与核心表达的相似度）

2. **扩展模型能力**
   - 增加模型层数和隐藏层维度
   - 添加更复杂的特征提取
   - 实现增量训练策略

3. **混合训练与优化**
   - 实现混合比例训练（核心+扩展）
   - 分析不同表达方式的识别准确率
   - 对难识别的表达方式添加更多样本
   - 迭代训练直到所有表达方式都达到良好准确率

4. **部署与监控**
   - 设计指标监控系统
   - 部署模型并持续收集用户数据
   - 根据实际使用数据继续优化模型
   - 建立持续改进流程

通过这些系统性方法，您将能够逐步构建一个高准确率的语音意图识别模型，既能精确识别核心说法，又能适应更多自然表达方式。
