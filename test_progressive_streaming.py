#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ¸è¿›å¼æµå¼è®­ç»ƒæµ‹è¯•è„šæœ¬
éªŒè¯æ–°å®ç°çš„æ¸è¿›å¼æµå¼è®­ç»ƒåŠŸèƒ½
"""

import torch
import numpy as np
from utils.progressive_streaming_trainer import (
    ProgressiveStreamingTrainer, 
    FinalPredictionLoss, 
    EdgeVoiceMetrics
)
from models.streaming_conformer import StreamingConformer
from config import *

def test_progressive_streaming_trainer():
    """æµ‹è¯•æ¸è¿›å¼æµå¼è®­ç»ƒå™¨"""
    print("=== æµ‹è¯•æ¸è¿›å¼æµå¼è®­ç»ƒå™¨ ===")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = ProgressiveStreamingTrainer()
    
    # æµ‹è¯•æµå¼æ¯”ä¾‹è°ƒåº¦
    print("\n1. æµ‹è¯•æµå¼æ¯”ä¾‹è°ƒåº¦:")
    for epoch in [1, 5, 10, 15, 20, 25, 30]:
        ratio = trainer.get_streaming_ratio(epoch)
        should_use = trainer.should_use_streaming(epoch)
        print(f"  Epoch {epoch:2d}: æµå¼æ¯”ä¾‹={ratio:.1f}, åº”è¯¥ä½¿ç”¨æµå¼={should_use}")
    
    # æµ‹è¯•åºåˆ—åˆ†å‰²
    print("\n2. æµ‹è¯•åºåˆ—åˆ†å‰²:")
    batch_size, seq_len, feature_dim = 2, 300, 96
    features = torch.randn(batch_size, seq_len, feature_dim)
    
    chunks = trainer.split_sequence_to_chunks(features)
    print(f"  è¾“å…¥åºåˆ—: {features.shape}")
    print(f"  åˆ†å‰²åchunksæ•°é‡: {len(chunks)}")
    for i, chunk in enumerate(chunks):
        print(f"    Chunk {i}: {chunk.shape}")
    
    return trainer

def test_final_prediction_loss():
    """æµ‹è¯•æœ€ç»ˆé¢„æµ‹æŸå¤±å‡½æ•°"""
    print("\n=== æµ‹è¯•æœ€ç»ˆé¢„æµ‹æŸå¤±å‡½æ•° ===")
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = FinalPredictionLoss()
    
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size, num_classes = 4, 8
    final_output = torch.randn(batch_size, num_classes)
    labels = torch.randint(0, num_classes, (batch_size,))
    
    # æ¨¡æ‹Ÿå¤šä¸ªchunkçš„è¾“å‡º
    all_outputs = [
        torch.randn(batch_size, num_classes),
        torch.randn(batch_size, num_classes),
        final_output
    ]
    
    # è®¡ç®—æŸå¤±
    loss_without_stability = criterion(final_output, labels)
    loss_with_stability = criterion(final_output, labels, all_outputs)
    
    print(f"  ä¸å«ç¨³å®šæ€§æŸå¤±: {loss_without_stability:.4f}")
    print(f"  åŒ…å«ç¨³å®šæ€§æŸå¤±: {loss_with_stability:.4f}")
    print(f"  ç¨³å®šæ€§æŸå¤±æƒé‡: {STABILITY_LOSS_WEIGHT}")
    
    return criterion

def test_edgevoice_metrics():
    """æµ‹è¯•EdgeVoiceè¯„ä¼°æŒ‡æ ‡"""
    print("\n=== æµ‹è¯•EdgeVoiceè¯„ä¼°æŒ‡æ ‡ ===")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    metrics = EdgeVoiceMetrics()
    
    # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
    intent_labels = ['TAKE_PHOTO', 'START_RECORDING', 'STOP_RECORDING', 
                    'CAPTURE_AND_DESCRIBE', 'OTHERS']
    
    predictions = [0, 1, 2, 0, 4, 1, 2, 3, 0, 1]  # æ¨¡æ‹Ÿé¢„æµ‹
    labels = [0, 1, 1, 0, 4, 1, 2, 3, 0, 2]       # æ¨¡æ‹ŸçœŸå®æ ‡ç­¾
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy_metrics = metrics.calculate_top1_accuracy(predictions, labels, intent_labels)
    print(f"  æ€»ä½“å‡†ç¡®ç‡: {accuracy_metrics['total_accuracy']:.2%}")
    print(f"  æ ¸å¿ƒæŒ‡ä»¤å‡†ç¡®ç‡: {accuracy_metrics['core_accuracy']:.2%}")
    print(f"  æ ¸å¿ƒæŒ‡ä»¤æ ·æœ¬æ•°: {accuracy_metrics['core_samples']}")
    
    # æ¨¡æ‹Ÿé¢„æµ‹åºåˆ—ï¼ˆç”¨äºç¨³å®šæ€§è¯„ä¼°ï¼‰
    prediction_sequences = [
        [0, 0, 0, 0],      # ç¨³å®šé¢„æµ‹
        [1, 2, 1, 1],      # æœ‰å˜åŒ–çš„é¢„æµ‹
        [3, 3, 4, 4],      # ä¸­é€”å˜åŒ–
        [2, 2, 2, 2]       # å®Œå…¨ç¨³å®š
    ]
    
    stability_metrics = metrics.calculate_stability_score(prediction_sequences)
    print(f"  ç¨³å®šæ€§è¯„åˆ†: {stability_metrics['stability_score']:.2%}")
    print(f"  å¹³å‡å˜åŒ–æ¬¡æ•°: {stability_metrics['avg_changes']:.1f}")
    
    # è®¡ç®—è¯¯è¯†åˆ«ç‡
    misid_metrics = metrics.calculate_misidentification_rate(predictions, labels, intent_labels)
    print(f"  æ€»ä½“è¯¯è¯†åˆ«ç‡: {misid_metrics['total_misidentification_rate']:.2%}")
    print(f"  æ ¸å¿ƒæŒ‡ä»¤è¯¯è¯†åˆ«ç‡: {misid_metrics['core_misidentification_rate']:.2%}")
    
    return metrics

def test_streaming_forward_pass():
    """æµ‹è¯•æµå¼å‰å‘ä¼ æ’­"""
    print("\n=== æµ‹è¯•æµå¼å‰å‘ä¼ æ’­ ===")
    
    # åˆ›å»ºæ¨¡å‹
    model = StreamingConformer(
        input_dim=N_MFCC * 3,
        hidden_dim=64,  # ä½¿ç”¨è¾ƒå°çš„éšè—å±‚ä»¥åŠ å¿«æµ‹è¯•
        num_classes=8,
        num_layers=2,   # ä½¿ç”¨è¾ƒå°‘å±‚æ•°ä»¥åŠ å¿«æµ‹è¯•
        num_heads=4,
        dropout=0.1,
        kernel_size=9,
        expansion_factor=2
    )
    model.eval()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ProgressiveStreamingTrainer()
    
    # æ¨¡æ‹Ÿè¾“å…¥
    batch_size, seq_len, feature_dim = 2, 250, N_MFCC * 3
    features = torch.randn(batch_size, seq_len, feature_dim)
    device = torch.device('cpu')
    
    print(f"  è¾“å…¥ç‰¹å¾å½¢çŠ¶: {features.shape}")
    
    try:
        # æ‰§è¡Œæµå¼å‰å‘ä¼ æ’­
        final_output, all_outputs = trainer.streaming_forward_pass(model, features, device)
        
        print(f"  æœ€ç»ˆè¾“å‡ºå½¢çŠ¶: {final_output.shape}")
        print(f"  æ€»chunkæ•°é‡: {len(all_outputs)}")
        print(f"  å„chunkè¾“å‡ºå½¢çŠ¶: {[output.shape for output in all_outputs]}")
        
        # éªŒè¯è¾“å‡ºåˆç†æ€§
        assert final_output.shape == (batch_size, 8), f"æœ€ç»ˆè¾“å‡ºå½¢çŠ¶é”™è¯¯: {final_output.shape}"
        assert len(all_outputs) > 0, "åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªchunkè¾“å‡º"
        
        print("  âœ… æµå¼å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"  âŒ æµå¼å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•æ¸è¿›å¼æµå¼è®­ç»ƒåŠŸèƒ½...\n")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        # æµ‹è¯•å„ä¸ªç»„ä»¶
        trainer = test_progressive_streaming_trainer()
        criterion = test_final_prediction_loss()
        metrics = test_edgevoice_metrics()
        
        # æµ‹è¯•æµå¼å‰å‘ä¼ æ’­
        streaming_success = test_streaming_forward_pass()
        
        if streaming_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¸è¿›å¼æµå¼è®­ç»ƒåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
            print("\nğŸ“‹ åŠŸèƒ½æ€»ç»“:")
            print("  âœ… æ¸è¿›å¼è®­ç»ƒè°ƒåº¦å™¨")
            print("  âœ… åºåˆ—åˆ†å‰²å’Œchunkå¤„ç†")
            print("  âœ… æœ€ç»ˆé¢„æµ‹æŸå¤±å‡½æ•°")
            print("  âœ… EdgeVoiceè¯„ä¼°æŒ‡æ ‡")
            print("  âœ… æµå¼å‰å‘ä¼ æ’­")
            
            print("\nğŸš€ å¯ä»¥å¼€å§‹ä½¿ç”¨æ¸è¿›å¼æµå¼è®­ç»ƒäº†ï¼")
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python train_streaming.py --annotation_file data/split/train_annotations.csv \\")
            print("                           --model_save_path saved_models/streaming_conformer_progressive.pt \\")
            print("                           --progressive_streaming \\")
            print("                           --num_epochs 30")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 